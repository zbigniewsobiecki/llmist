---
title: Models & Aliases
description: Complete reference for all supported models and their aliases
sidebar:
  order: 1
---

import { Aside, Badge, Tabs, TabItem } from '@astrojs/starlight/components';

llmist supports multiple LLM providers with convenient aliases for quick access.

## Model Aliases

Use short aliases instead of full model names:

| Alias | Full Model Name | Provider |
|-------|----------------|----------|
| `gpt5` | `gpt-5` | OpenAI |
| `gpt5-mini` | `gpt-5-mini` | OpenAI |
| `gpt4o` | `gpt-4o` | OpenAI |
| `gpt4-turbo` | `gpt-4-turbo` | OpenAI |
| `o3-mini` | `o3-mini` | OpenAI |
| `sonnet` | `claude-sonnet-4-5` | Anthropic |
| `opus` | `claude-opus-4-5` | Anthropic |
| `haiku` | `claude-haiku-4-5` | Anthropic |
| `flash` | `gemini-2.5-flash` | Google |
| `pro` | `gemini-3-pro-preview` | Google |

<Aside type="tip">
  Use aliases for quick prototyping: `--model sonnet` instead of `--model anthropic:claude-sonnet-4-5`
</Aside>

## Provider-Prefixed Models

For explicit provider selection, use the `provider:model` format:

```bash
# Explicit provider selection
llmist complete "Hello" --model openai:gpt-5
llmist complete "Hello" --model anthropic:claude-sonnet-4-5
llmist complete "Hello" --model gemini:gemini-2.5-flash
```

## Model Capabilities

| Model | Vision | Streaming | Tool Use | Context |
|-------|--------|-----------|----------|---------|
| GPT-5 | ✓ | ✓ | ✓ | 128K |
| GPT-5 Mini | ✓ | ✓ | ✓ | 128K |
| GPT-4o | ✓ | ✓ | ✓ | 128K |
| Claude Opus 4.5 | ✓ | ✓ | ✓ | 200K |
| Claude Sonnet 4.5 | ✓ | ✓ | ✓ | 200K |
| Claude Haiku 4.5 | ✓ | ✓ | ✓ | 200K |
| Gemini Flash | ✓ | ✓ | ✓ | 1M |
| Gemini Pro | ✓ | ✓ | ✓ | 1M |

## Recommended Models by Use Case

| Use Case | Recommended | Why |
|----------|-------------|-----|
| **General tasks** | `sonnet` | Best balance of quality and speed |
| **Complex reasoning** | `opus` | Highest capability |
| **High-volume tasks** | `haiku`, `flash` | Fast and cost-effective |
| **Long documents** | `flash`, `pro` | 1M token context |
| **Coding** | `sonnet`, `gpt5` | Strong code understanding |
| **Vision tasks** | `gpt4o`, `flash` | Excellent image analysis |

## Image Generation Models

| Model | Provider | Description |
|-------|----------|-------------|
| `dall-e-3` | OpenAI | High-quality image generation |
| `dall-e-2` | OpenAI | Faster, lower cost |
| `imagen-3` | Google | Gemini image generation |

## Speech Models

| Model | Provider | Description |
|-------|----------|-------------|
| `tts-1` | OpenAI | Text-to-speech, standard quality |
| `tts-1-hd` | OpenAI | Text-to-speech, high quality |

## Usage Examples

<Tabs>
  <TabItem label="Library">
    ```typescript
    import { LLMist } from 'llmist';

    // Using alias
    const answer = await LLMist.createAgent()
      .withModel('sonnet')
      .askAndCollect('Hello!');

    // Using full name
    const answer2 = await LLMist.createAgent()
      .withModel('anthropic:claude-sonnet-4-5')
      .askAndCollect('Hello!');
    ```
  </TabItem>
  <TabItem label="CLI">
    ```bash
    # Using alias
    llmist complete "Hello" --model sonnet

    # Using full name
    llmist complete "Hello" --model anthropic:claude-sonnet-4-5
    ```
  </TabItem>
</Tabs>

## Auto-Discovery

llmist automatically discovers available providers based on environment variables:

| Variable | Provider |
|----------|----------|
| `OPENAI_API_KEY` | OpenAI |
| `ANTHROPIC_API_KEY` | Anthropic |
| `GEMINI_API_KEY` | Google Gemini |

See [Environment Variables](/reference/environment/) for complete configuration.
